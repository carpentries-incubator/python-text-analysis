<!DOCTYPE html>
<!-- START: inst/pkgdown/templates/layout.html --><!-- Generated by pkgdown: do not edit by hand --><html lang="en" data-bs-theme="auto"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><title>Text Analysis in Python: Finetuning LLMs</title><meta name="viewport" content="width=device-width, initial-scale=1"><script src="assets/themetoggle.js"></script><link rel="stylesheet" type="text/css" href="assets/styles.css"><script src="assets/scripts.js" type="text/javascript"></script><!-- mathjax --><script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      config: ["MMLorHTML.js"],
      jax: ["input/TeX","input/MathML","output/HTML-CSS","output/NativeMML", "output/PreviewHTML"],
      extensions: ["tex2jax.js","mml2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
      TeX: {
        extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]
      },
      tex2jax: {
        inlineMath: [['\\(', '\\)']],
        displayMath: [ ['$$','$$'], ['\\[', '\\]'] ],
        processEscapes: true
      }
    });
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><!-- Responsive Favicon for The Carpentries --><link rel="apple-touch-icon" sizes="180x180" href="favicons/cp/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="favicons/cp/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="favicons/cp/favicon-16x16.png"><link rel="manifest" href="favicons/cp/site.webmanifest"><link rel="mask-icon" href="favicons/cp/safari-pinned-tab.svg" color="#5bbad5"><meta name="msapplication-TileColor" content="#da532c"><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"><meta name="theme-color" media="(prefers-color-scheme: dark)" content="black"></head><body>
    <header id="top" class="navbar navbar-expand-md top-nav carpentries"><svg xmlns="http://www.w3.org/2000/svg" class="d-none"><symbol id="check2" viewbox="0 0 16 16"><path d="M13.854 3.646a.5.5 0 0 1 0 .708l-7 7a.5.5 0 0 1-.708 0l-3.5-3.5a.5.5 0 1 1 .708-.708L6.5 10.293l6.646-6.647a.5.5 0 0 1 .708 0z"></path></symbol><symbol id="circle-half" viewbox="0 0 16 16"><path d="M8 15A7 7 0 1 0 8 1v14zm0 1A8 8 0 1 1 8 0a8 8 0 0 1 0 16z"></path></symbol><symbol id="moon-stars-fill" viewbox="0 0 16 16"><path d="M6 .278a.768.768 0 0 1 .08.858 7.208 7.208 0 0 0-.878 3.46c0 4.021 3.278 7.277 7.318 7.277.527 0 1.04-.055 1.533-.16a.787.787 0 0 1 .81.316.733.733 0 0 1-.031.893A8.349 8.349 0 0 1 8.344 16C3.734 16 0 12.286 0 7.71 0 4.266 2.114 1.312 5.124.06A.752.752 0 0 1 6 .278z"></path><path d="M10.794 3.148a.217.217 0 0 1 .412 0l.387 1.162c.173.518.579.924 1.097 1.097l1.162.387a.217.217 0 0 1 0 .412l-1.162.387a1.734 1.734 0 0 0-1.097 1.097l-.387 1.162a.217.217 0 0 1-.412 0l-.387-1.162A1.734 1.734 0 0 0 9.31 6.593l-1.162-.387a.217.217 0 0 1 0-.412l1.162-.387a1.734 1.734 0 0 0 1.097-1.097l.387-1.162zM13.863.099a.145.145 0 0 1 .274 0l.258.774c.115.346.386.617.732.732l.774.258a.145.145 0 0 1 0 .274l-.774.258a1.156 1.156 0 0 0-.732.732l-.258.774a.145.145 0 0 1-.274 0l-.258-.774a1.156 1.156 0 0 0-.732-.732l-.774-.258a.145.145 0 0 1 0-.274l.774-.258c.346-.115.617-.386.732-.732L13.863.1z"></path></symbol><symbol id="sun-fill" viewbox="0 0 16 16"><path d="M8 12a4 4 0 1 0 0-8 4 4 0 0 0 0 8zM8 0a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-1 0v-2A.5.5 0 0 1 8 0zm0 13a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-1 0v-2A.5.5 0 0 1 8 13zm8-5a.5.5 0 0 1-.5.5h-2a.5.5 0 0 1 0-1h2a.5.5 0 0 1 .5.5zM3 8a.5.5 0 0 1-.5.5h-2a.5.5 0 0 1 0-1h2A.5.5 0 0 1 3 8zm10.657-5.657a.5.5 0 0 1 0 .707l-1.414 1.415a.5.5 0 1 1-.707-.708l1.414-1.414a.5.5 0 0 1 .707 0zm-9.193 9.193a.5.5 0 0 1 0 .707L3.05 13.657a.5.5 0 0 1-.707-.707l1.414-1.414a.5.5 0 0 1 .707 0zm9.193 2.121a.5.5 0 0 1-.707 0l-1.414-1.414a.5.5 0 0 1 .707-.707l1.414 1.414a.5.5 0 0 1 0 .707zM4.464 4.465a.5.5 0 0 1-.707 0L2.343 3.05a.5.5 0 1 1 .707-.707l1.414 1.414a.5.5 0 0 1 0 .708z"></path></symbol></svg><a class="visually-hidden-focusable skip-link" href="#main-content">Skip to main content</a>
  <div class="container-fluid top-nav-container">
    <div class="col-md-8">
      <div class="large-logo">
        <img id="cp-logo" alt="Lesson Description" src="assets/images/carpentries-logo.svg"><span class="badge text-bg-info">
          <abbr title="This lesson is in the beta phase, which means that it is ready for teaching by instructors outside of the original author team.">
            <a href="https://docs.carpentries.org/resources/curriculum/lesson-life-cycle.html" class="external-link alert-link">
              <i aria-hidden="true" class="icon" data-feather="alert-circle" style="border-radius: 5px"></i>
              Beta
            </a>
            <span class="visually-hidden">This lesson is in the beta phase, which means that it is ready for teaching by instructors outside of the original author team.</span>
          </abbr>
        </span>

      </div>
    </div>
    <div class="selector-container">
      <div id="theme-selector">
        <li class="nav-item dropdown" id="theme-button-list">
          <button class="btn btn-link nav-link px-0 px-lg-2 dropdown-toggle d-flex align-items-center" id="bd-theme" type="button" aria-expanded="false" data-bs-toggle="dropdown" data-bs-display="static" aria-label="Toggle theme (auto)">
            <svg class="bi my-1 theme-icon-active"><use href="#circle-half"></use></svg><i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="bd-theme-text"><li>
              <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="light" aria-pressed="false">
                <svg class="bi me-2 theme-icon"><use href="#sun-fill"></use></svg>
                Light
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
            <li>
              <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="dark" aria-pressed="false">
                <svg class="bi me-2 theme-icon"><use href="#moon-stars-fill"></use></svg>
                Dark
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
            <li>
              <button type="button" class="btn dropdown-item d-flex align-items-center active" data-bs-theme-value="auto" aria-pressed="true">
                <svg class="bi me-2 theme-icon"><use href="#circle-half"></use></svg>
                Auto
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
          </ul></li>
      </div>


      <div class="dropdown" id="instructor-dropdown">
        <button class="btn btn-secondary dropdown-toggle bordered-button" type="button" id="dropdownMenu1" data-bs-toggle="dropdown" aria-expanded="false">
          <i aria-hidden="true" class="icon" data-feather="eye"></i> Learner View <i data-feather="chevron-down"></i>
        </button>
        <ul class="dropdown-menu" aria-labelledby="dropdownMenu1"><li><button class="dropdown-item" type="button" onclick="window.location.href='instructor/10-finetuning-transformers.html';">Instructor View</button></li>
        </ul></div>
    </div>
  </div>
  <hr></header><nav class="navbar navbar-expand-xl bottom-nav carpentries" aria-label="Main Navigation"><div class="container-fluid nav-container">
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle Navigation">
      <span class="navbar-toggler-icon"></span>
      <span class="menu-title">Menu</span>
    </button>
    <div class="nav-logo">
      <img class="small-logo" alt="Lesson Description" src="assets/images/carpentries-logo-sm.svg"></div>
    <div class="lesson-title-md">
      Text Analysis in Python
    </div>
    <div class="search-icon-sm">
      <!-- TODO: do not show until we have search
        <i role="img" aria-label="Search the All In One page" data-feather="search"></i>
      -->
    </div>
    <div class="desktop-nav">
      <ul class="navbar-nav me-auto mb-2 mb-lg-0"><li class="nav-item">
          <span class="lesson-title">
            Text Analysis in Python
          </span>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="key-points.html">Key Points</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="reference.html#glossary">Glossary</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="profiles.html">Learner Profiles</a>
        </li>
        <li class="nav-item dropdown">
          <button class="nav-link dropdown-toggle" id="navbarDropdown" data-bs-toggle="dropdown" aria-expanded="false">
            More <i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu" aria-labelledby="navbarDropdown"><li><a class="dropdown-item" href="discuss.html">Discussion</a></li><li><a class="dropdown-item" href="reference.html">Glossary</a></li>
          </ul></li>
      </ul></div>
    <!--
    <form class="d-flex col-md-2 search-form">
      <fieldset disabled>
      <input class="form-control me-2 searchbox" type="search" placeholder="" aria-label="">
        <button class="btn btn-outline-success tablet-search-button"  type="submit">
          <i class="search-icon" data-feather="search" role="img" aria-label="Search the All In One page"></i>
        </button>
      </fieldset>
    </form>
    -->
    <a id="search-button" class="btn btn-primary" href="aio.html" role="button" aria-label="Search the All In One page">Search the All In One page</a>
  </div><!--/div.container-fluid -->
</nav><div class="col-md-12 mobile-title">
  Text Analysis in Python
</div>

<aside class="col-md-12 lesson-progress"><div style="width: 67%" class="percentage">
    67%
  </div>
  <div class="progress carpentries">
    <div class="progress-bar carpentries" role="progressbar" style="width: 67%" aria-valuenow="67" aria-label="Lesson Progress" aria-valuemin="0" aria-valuemax="100">
    </div>
  </div>
</aside><div class="container">
      <div class="row">
        <!-- START: inst/pkgdown/templates/navbar.html -->
<div id="sidebar-col" class="col-lg-4">
  <div id="sidebar" class="sidebar">
      <nav aria-labelledby="flush-headingEleven"><button role="button" aria-label="close menu" alt="close menu" aria-expanded="true" aria-controls="sidebar" class="collapse-toggle" data-collapse="Collapse " data-episodes="Episodes ">
          <i class="search-icon" data-feather="x" role="img"></i>
        </button>
        <div class="sidebar-inner">
          <div class="row mobile-row" id="theme-row-mobile">
            <div class="col" id="theme-selector">
              <li class="nav-item dropdown" id="theme-button-list">
                <button class="btn btn-link nav-link px-0 px-lg-2 dropdown-toggle d-flex align-items-center" id="bd-theme" type="button" aria-expanded="false" data-bs-toggle="dropdown" data-bs-display="static" aria-label="Toggle theme (auto)">
                  <svg class="bi my-1 theme-icon-active"><use href="#circle-half"></use></svg><span class="d-lg-none ms-1" id="bd-theme-text">Toggle Theme</span>
                </button>
                <ul class="dropdown-menu dropdown-menu-right" aria-labelledby="bd-theme-text"><li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="light" aria-pressed="false">
                      <svg class="bi me-2 theme-icon"><use href="#sun-fill"></use></svg>
                      Light
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                  <li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="dark" aria-pressed="false">
                      <svg class="bi me-2 theme-icon"><use href="#moon-stars-fill"></use></svg>
                      Dark
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                  <li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center active" data-bs-theme-value="auto" aria-pressed="true">
                      <svg class="bi me-2 theme-icon"><use href="#circle-half"></use></svg>
                      Auto
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                </ul></li>
            </div>
          </div>
          <div class="row mobile-row">
            <div class="col">
              <div class="sidenav-view-selector">
                <div class="accordion accordion-flush" id="accordionFlush9">
                  <div class="accordion-item">
                    <h2 class="accordion-header" id="flush-headingNine">
                      <button class="accordion-button collapsed" id="instructor" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseNine" aria-expanded="false" aria-controls="flush-collapseNine">
                        <i id="eye" aria-hidden="true" class="icon" data-feather="eye"></i> Learner View
                      </button>
                    </h2>
                    <div id="flush-collapseNine" class="accordion-collapse collapse" aria-labelledby="flush-headingNine" data-bs-parent="#accordionFlush2">
                      <div class="accordion-body">
                        <a href="instructor/10-finetuning-transformers.html">Instructor View</a>
                      </div>
                    </div>
                  </div><!--/div.accordion-item-->
                </div><!--/div.accordion-flush-->
              </div><!--div.sidenav-view-selector -->
            </div><!--/div.col -->

            <hr></div><!--/div.mobile-row -->

          <div class="accordion accordion-flush" id="accordionFlush11">
            <div class="accordion-item">

              <button id="chapters" class="accordion-button show" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseEleven" aria-expanded="false" aria-controls="flush-collapseEleven">
                <h2 class="accordion-header chapters" id="flush-headingEleven">
                  EPISODES
                </h2>
              </button>
              <div id="flush-collapseEleven" class="accordion-collapse show collapse" aria-labelledby="flush-headingEleven" data-bs-parent="#accordionFlush11">

                <div class="accordion-body">
                  <div class="accordion accordion-flush" id="accordionFlush1">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading1">
        <a href="index.html">Summary and Setup</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush2">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading2">
        <a href="01-basicConcepts.html">1. Introduction to Natural Language Processing</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush3">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading3">
        <a href="02-apis.html">2. Corpus Development- Text Data Collection</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush4">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading4">
        <a href="03-preprocessing.html">3. Preparing and Preprocessing Your Data</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush5">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading5">
        <a href="04-vectorSpace.html">4. Vector Space and Distance</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush6">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading6">
        <a href="05-tf-idf-documentEmbeddings.html">5. Document Embeddings and TF-IDF</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush7">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading7">
        <a href="06-lsa.html">6. Latent Semantic Analysis</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush8">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading8">
        <a href="07-wordEmbed_intro.html">7. Intro to Word Embeddings</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush9">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading9">
        <a href="08-wordEmbed_word2vec-algorithm.html">8. The Word2Vec Algorithm</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush10">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading10">
        <a href="09-wordEmbed_train-word2vec.html">9. Training Word2Vec</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlushcurrent">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-headingcurrent">
      <button class="accordion-button" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapsecurrent" aria-expanded="true" aria-controls="flush-collapsecurrent">
        <span class="visually-hidden">Current Chapter</span>
        <span class="current-chapter">
        10. Finetuning LLMs
        </span>
      </button>
    </div><!--/div.accordion-header-->

    <div id="flush-collapsecurrent" class="accordion-collapse collapse show" aria-labelledby="flush-headingcurrent" data-bs-parent="#accordionFlushcurrent">
      <div class="accordion-body">
        <ul><li><a href="#setup">Setup</a></li>
<li><a href="#finetuning-llms">Finetuning LLMs</a></li>
<li><a href="#using-existing-model--distilbert">Using Existing Model- DistilBERT</a></li>
<li><a href="#the-interpretive-loop">The Interpretive Loop</a></li>
<li><a href="#nlp-task">NLP task</a></li>
<li><a href="#examining-working-example">Examining Working Example</a></li>
<li><a href="#creating-training-data">Creating training data</a></li>
<li><a href="#tagging-a-dataset">Tagging a dataset</a></li>
<li><a href="#export-to-desired-format">Export to desired format</a></li>
<li><a href="#loading-our-custom-dataset">Loading our custom dataset</a></li>
<li><a href="#huggingface-code">HuggingFace Code</a></li>
<li><a href="#preprocessing-the-data">Preprocessing the data</a></li>
<li><a href="#fine-tuning-the-model">Fine-tuning the model</a></li>
<li><a href="#collator">Collator</a></li>
<li><a href="#metrics">Metrics</a></li>
<li><a href="#post-processing">Post Processing</a></li>
<li><a href="#evaluation-metrics-for-ner">Evaluation Metrics for NER</a></li>
<li><a href="#using-our-model">Using our Model</a></li>
<li><a href="#outro">Outro</a></li>
        </ul></div><!--/div.accordion-body-->
    </div><!--/div.accordion-collapse-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush12">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading12">
        <a href="11-ethics.html">11. Ethics and Text Analysis</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

                </div>
              </div>
            </div>

            <hr class="half-width"><div class="accordion accordion-flush lesson-resources" id="accordionFlush12">
              <div class="accordion-item">
                <h2 class="accordion-header" id="flush-headingTwelve">
                  <button class="accordion-button collapsed" id="lesson-resources" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseTwelve" aria-expanded="false" aria-controls="flush-collapseTwelve">
                    RESOURCES
                  </button>
                </h2>
                <div id="flush-collapseTwelve" class="accordion-collapse collapse" aria-labelledby="flush-headingTwelve" data-bs-parent="#accordionFlush12">
                  <div class="accordion-body">
                    <ul><li>
                        <a href="key-points.html">Key Points</a>
                      </li>
                      <li>
                        <a href="reference.html#glossary">Glossary</a>
                      </li>
                      <li>
                        <a href="profiles.html">Learner Profiles</a>
                      </li>
                      <li><a href="discuss.html">Discussion</a></li><li><a href="reference.html">Glossary</a></li>
                    </ul></div>
                </div>
              </div>
            </div>
            <hr class="half-width lesson-resources"><a href="aio.html">See all in one page</a>


            <hr class="d-none d-sm-block d-md-none"><div class="d-grid gap-1">

            </div>
          </div><!-- /div.accordion -->
        </div><!-- /div.sidebar-inner -->
      </nav></div><!-- /div.sidebar -->
  </div><!-- /div.sidebar-col -->
<!-- END:   inst/pkgdown/templates/navbar.html-->

        <!-- START: inst/pkgdown/templates/content-instructor.html -->
  <div class="col-xl-8 col-lg-12 primary-content">
    <nav class="lesson-content mx-md-4" aria-label="Previous and Next Chapter"><!-- content for small screens --><div class="d-block d-sm-block d-md-none">
        <a class="chapter-link" href="09-wordEmbed_train-word2vec.html"><i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>Previous</a>
        <a class="chapter-link float-end" href="11-ethics.html">Next<i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i></a>
      </div>
      <!-- content for large screens -->
      <div class="d-none d-sm-none d-md-block">
        <a class="chapter-link" href="09-wordEmbed_train-word2vec.html" rel="prev">
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>
          Previous: Training Word2Vec
        </a>
        <a class="chapter-link float-end" href="11-ethics.html" rel="next">
          Next: Ethics and Text...
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i>
        </a>
      </div>
      <hr></nav><main id="main-content" class="main-content"><div class="container lesson-content">
        <h1>Finetuning LLMs</h1>
        <p>Last updated on 2025-05-01 |

        <a href="https://github.com/carpentries-incubator/python-text-analysis/edit/main/episodes/10-finetuning-transformers.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>



        <div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>

        

<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul><li>How can I fine-tune preexisting LLMs for my own research?</li>
<li>How do I pick the right data format?</li>
<li>How do I create my own labels?</li>
<li>How do I put my data into a model for finetuning?</li>
<li>How do I evaluate success at my task?</li>
</ul></div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul><li>Examine CONLL2003 data.</li>
<li>Learn about Label Studio.</li>
<li>Learn about finetuning a BERT model.</li>
</ul></div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="setup">Setup<a class="anchor" aria-label="anchor" href="#setup"></a></h2>
<hr class="half-width"><p>If you are running this lesson on Google Colab, it is strongly
recommended that you enable GPU acceleration. If you are running locally
without CUDA, you should be able to run most of the commands, but
training will take a long time and you will want to use the pretrained
model when using it.</p>
<p>To enable GPU, click “Edit &gt; Notebook settings” and select GPU. If
enabled, this command will return a status window and not an error:</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="op">!</span>nvidia<span class="op">-</span>smi</span></code></pre>
</div>
<pre><code>Thu Mar 28 20:50:47 2024
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |
| N/A   64C    P8              11W /  70W |      0MiB / 15360MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+

+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+</code></pre>
<p>These installation commands will take time to run. Begin them
now.</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="op">!</span>pip install transformers datasets evaluate seqeval</span></code></pre>
</div>
</section><section><h2 class="section-heading" id="finetuning-llms">Finetuning LLMs<a class="anchor" aria-label="anchor" href="#finetuning-llms"></a></h2>
<hr class="half-width"><p>In 2017, a revolutionary breakthrough for NLP occurred. A new type of
hidden layer for neural networks called Transfomers were invented.
Transformers made processing huge amounts of data feasible for the first
time.</p>
<p>Large Language Models, or LLMs, were the result. LLMs are the current
state of the art when it comes to many tasks, and although LLMs can
differ, they are mostly based on a similar architecture to one another.
We will be looking at an influential LLM called BERT.</p>
<figure><img src="fig/10-bert-fine-tune.png" alt="BERT fine-tune" class="figure mx-auto d-block"></figure><p>Training these models from scratch requires a huge amount of data and
compute power. The majority of work is done for the many hidden layers
of the model. However, by tweaking only the output layer, BERT can
effectively perform many tasks with a minimal amount of data. This
process of adapting an LLM is called <strong>fine-tuning</strong>.</p>
<p>Because of this, we will not be writing the code for this lesson from
scratch. Rather, this lesson will focus on creating our own data,
adapting existing code and modifying it to achieve the task we want to
accomplish.</p>
</section><section><h2 class="section-heading" id="using-existing-model--distilbert">Using Existing Model- DistilBERT<a class="anchor" aria-label="anchor" href="#using-existing-model--distilbert"></a></h2>
<hr class="half-width"><p>We will be using a miniture LLM called DistilBERT for this lesson. We
are using the “uncased” version of distilbert, which removes
capitalization.</p>
<p>Much like many of our models, DistilBERT is available through
HuggingFace. <a href="https://huggingface.co/docs/transformers/model_doc/distilbert" class="external-link uri">https://huggingface.co/docs/transformers/model_doc/distilbert</a></p>
<p>Let’s start by importing the library, and importing both the
pretrained model and the tokenizer that BERT uses.</p>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoTokenizer, AutoModelForTokenClassification</span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> pipeline</span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(<span class="st">"Davlan/distilbert-base-multilingual-cased-ner-hrl"</span>)</span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a>model <span class="op">=</span> AutoModelForTokenClassification.from_pretrained(<span class="st">"Davlan/distilbert-base-multilingual-cased-ner-hrl"</span>)</span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a><span class="co">#The aggregation strategy combines all of the tokens with a given label. Useful when our tokenizer uses subword tokens.</span></span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a>nlp <span class="op">=</span> pipeline(<span class="st">"ner"</span>, model<span class="op">=</span>model, tokenizer<span class="op">=</span>tokenizer, aggregation_strategy<span class="op">=</span><span class="st">'simple'</span>)</span></code></pre>
</div>
<p>Next, we’ll use the tokenizer to preprocess our example sentence.</p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a>example <span class="op">=</span> <span class="st">"Nader Jokhadar had given Syria the lead with a well-struck header in the seventh minute."</span></span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>ner_results <span class="op">=</span> nlp(example)</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a><span class="cf">for</span> result <span class="kw">in</span> ner_results:</span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a>  <span class="bu">print</span>(result)</span></code></pre>
</div>
<p>LLMs are highly performant at not just one, but a variety of tasks.
And there are many versions of LLMs, designed to perform well on a
variety of tasks available on HuggingFace.</p>
<p>We could use this existing model for research purposes as is. We
might use an existing NER model to find examples of the most common
locations in a set of fiction. You could categorize product reviews as
positive or negative automatically using sentiment analysis. You could
automatically translate documents from one language to another.</p>
<p>There are many possible tasks that LLMs can handle!</p>
<div class="section level3">
<h3 id="why-fine-tune">Why Fine Tune?<a class="anchor" aria-label="anchor" href="#why-fine-tune"></a></h3>
<p>Given that there are many many prebuilt models for BERT, why would
you want to go through the trouble of fine tuning your own?</p>
<p>LLM’s are very robust. They aren’t just capable of doing tasks other
people have already trained them for. LLMs can also do specific and
novel tasks you might want to accomplish as part of research!</p>
<p>Imagine using a LLM to classify a group of documents using training
data you create. Or imagine an LLM pulling out specific types of words
based on examples you provide. LLM’s can be trained to do these specific
tasks fairly well, without needing terabytes of data to do so.</p>
<p>Let’s take a look on how we fine tune an LLM on a novel task by
walking through an example.</p>
</div>
</section><section><h2 class="section-heading" id="the-interpretive-loop">The Interpretive Loop<a class="anchor" aria-label="anchor" href="#the-interpretive-loop"></a></h2>
<hr class="half-width"><p>To fine-tune, we will walk through all of the steps of our
interpretive loop diagram. Let’s take a look at our diagram once
more:</p>
<figure><img src="fig/01-Interpretive_Loop.JPG" alt="BERT fine-tune" class="figure mx-auto d-block"></figure><p>If no existing model does a given task, we can fine-tune a LLM to do
it. How do we start? We’re going to create versions of all the items
listed in our diagram.</p>
<p>We need the following: 1. A task, so we can find a model and LLM
pipeline to finetune. 2. A dataset for our task, properly formatted in a
way BERT can interpret. 3. A tokenizer and helpers to preprocess our
data in a way BERT expects. 4. A model that has been pretrained on
millions of documents for us. We will only fine-tune this model, not
recreate it from scratch. 5. A trainer to fine-tune our model to perform
our task. 6. A set of metrics so that we can evaluate how well our model
performs.</p>
<p>The final product of all this work will be a fine-tuned model that
classifies all the elements of reviews that we want. Let’s get
started!</p>
</section><section><h2 class="section-heading" id="nlp-task">NLP task<a class="anchor" aria-label="anchor" href="#nlp-task"></a></h2>
<hr class="half-width"><p>The first thing we can do is identify our task. Suppose our research
question is to look carefully at different elements of restaurant
reviews. We want to classify different elements of restaurant reviews,
such as amenities, locations, ratings, cuisine types and so on using an
LLM.</p>
<p>Our task here is Token Classification, or more specifically, Named
Entity Recognition. Classifying tokens will enable us to pull out
categories that are of interest to us.</p>
<p>The standard set of Named Entity Recognition labels is designed to be
broad: people, organizations and so on. However, it doesn’t have to be.
We can define our own entities of interest and have our model search for
them.</p>
<p>Now that we have an idea of what we’re aiming to do, lets look at
some of the LLMs provided by HuggingFace that perform this activity.
HuggingFace hosts many instructional Colab notebooks available at: <a href="https://huggingface.co/docs/transformers/notebooks" class="external-link uri">https://huggingface.co/docs/transformers/notebooks</a>.</p>
<p>We can find an example of Token Classification using PyTorch there.
This document will be the basis for our code.</p>
</section><section><h2 class="section-heading" id="examining-working-example">Examining Working Example<a class="anchor" aria-label="anchor" href="#examining-working-example"></a></h2>
<hr class="half-width"><p>Looking at the notebook, we can get an idea of how it functions and
adapt it for our own purposes.</p>
<ol style="list-style-type: decimal"><li>The existing model it uses is a compressed version of BERT,
“distilbert.” While not as accurate as the full BERT model, it is
smaller and easier to fine tune. We’ll use this model as well.</li>
<li>The existing dataset for our task is something called “conll2003”.
We will want to look at this and replace it with our own data, taking
care to copy the formatting of existing data.</li>
<li>The existing tokenizer requires a special helper method called an
aligner. We will copy this directly.</li>
<li>The existing model that we will tweak to accomplish our task.</li>
<li>A trainer, which will largely use existing parameters. We will need
to tweak our output labels for our new data.</li>
<li>The existing metrics will be fine, but we have to feed them into our
trainer.</li>
</ol></section><section><h2 class="section-heading" id="creating-training-data">Creating training data<a class="anchor" aria-label="anchor" href="#creating-training-data"></a></h2>
<hr class="half-width"><p>It’s a good idea to pattern your data output based on what the model
is expecting. You will need to make adjustments, but if you have
selected a model that is appropriate to the task you can reuse most of
the code already in place. We’ll start by installing our
dependencies.</p>
<p>Now, let’s take a look at the example data from the dataset used in
the example. The dataset used is called the CoNLL2003 dataset.</p>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="im">from</span> datasets <span class="im">import</span> load_dataset</span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a>ds <span class="op">=</span> load_dataset(<span class="st">"conll2003"</span>, trust_remote_code<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a><span class="bu">print</span>(ds)</span></code></pre>
</div>
<p>We can see that the CONLL dataset is split into three sets- training
data, validation data, and test data. Training data should make up about
80% of your corpus and is fed into the model to fine tune it. Validation
data should be about 10%, and is used to check how the training progress
is going as the model is trained. The test data is about 10% withheld
until the model is fully trained and ready for testing, so you can see
how it handles new documents that the model has never seen before.</p>
<p>Let’s take a closer look at a record in the train set so we can get
an idea of what our data should look like. The NER tags are the ones we
are interested in, so lets print them out and take a look. We’ll also
select the dataset and then an index for the document to look at an
example.</p>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a>traindoc <span class="op">=</span> ds[<span class="st">"train"</span>][<span class="dv">0</span>]</span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a>conll_tags <span class="op">=</span> ds[<span class="st">"train"</span>].features[<span class="ss">f"ner_tags"</span>].feature.names</span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a><span class="bu">print</span>(traindoc[<span class="st">'tokens'</span>])</span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a><span class="bu">print</span>(traindoc[<span class="st">'ner_tags'</span>])</span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a><span class="bu">print</span>(conll_tags)</span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a><span class="bu">print</span>()</span>
<span id="cb7-8"><a href="#cb7-8" tabindex="-1"></a></span>
<span id="cb7-9"><a href="#cb7-9" tabindex="-1"></a><span class="cf">for</span> token, ner_tag <span class="kw">in</span> <span class="bu">zip</span>(traindoc[<span class="st">'tokens'</span>], traindoc[<span class="st">'ner_tags'</span>]):</span>
<span id="cb7-10"><a href="#cb7-10" tabindex="-1"></a>  <span class="bu">print</span>(token<span class="op">+</span><span class="st">" "</span><span class="op">+</span>conll_tags[ner_tag])</span></code></pre>
</div>
<p>Each document has it’s own ID number. We can see that the tokens are
a list of words in the document. For each word in the tokens, there are
a series of numbers. Those numbers correspond to the labels in the
database. Based on this, we can see that the EU is recognized as an ORG
and the terms “German” and “British” are labelled as MISC.</p>
<p>These datasets are loaded using specially written loading scripts. We
can look at this script by searching for the ‘conll2003’ in huggingface
and selecting “Files”. The loading script is always named after the
dataset. In this case it is “conll2003.py”.</p>
<p><a href="https://huggingface.co/datasets/conll2003/blob/main/conll2003.py" class="external-link uri">https://huggingface.co/datasets/conll2003/blob/main/conll2003.py</a></p>
<p>Opening this file up, we can see that a zip file is downloaded and
text files are extracted. We can manually download this ourselves if we
would really like to take a closer look. For the sake of convienence,
the example we looked just looked at is reproduced below:</p>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="co">"""</span></span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a><span class="co">-DOCSTART- -X- -X- O</span></span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a><span class="co">EU NNP B-NP B-ORG</span></span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a><span class="co">rejects VBZ B-VP O</span></span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a><span class="co">German JJ B-NP B-MISC</span></span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a><span class="co">call NN I-NP O</span></span>
<span id="cb8-8"><a href="#cb8-8" tabindex="-1"></a><span class="co">to TO B-VP O</span></span>
<span id="cb8-9"><a href="#cb8-9" tabindex="-1"></a><span class="co">boycott VB I-VP O</span></span>
<span id="cb8-10"><a href="#cb8-10" tabindex="-1"></a><span class="co">British JJ B-NP B-MISC</span></span>
<span id="cb8-11"><a href="#cb8-11" tabindex="-1"></a><span class="co">lamb NN I-NP O</span></span>
<span id="cb8-12"><a href="#cb8-12" tabindex="-1"></a><span class="co">. . O O</span></span>
<span id="cb8-13"><a href="#cb8-13" tabindex="-1"></a><span class="co">"""</span></span></code></pre>
</div>
<pre><code><span><span class="st">'\n-DOCSTART- -X- -X- O\n\nEU NNP B-NP B-ORG\nrejects VBZ B-VP O\nGerman JJ B-NP B-MISC\ncall NN I-NP O\nto TO B-VP O\nboycott VB I-VP O\nBritish JJ B-NP B-MISC\nlamb NN I-NP O\n. . O O\n'</span></span></code></pre>
<p>This is a simple format, similar to a CSV. Each document is seperated
by a blank line. The token we look at is first, then space seperated
tags for POS, chunk_tags and NER tags. Many of the token classifications
use BIO tagging, which specifies that “B” is the beginning of a tag, “I”
is inside a tag, and “O” means that the token outside of our tagging
schema.</p>
<p>So, now that we have an idea of what the HuggingFace models expect,
let’s start thinking about how we can create our own set of data and
labels.</p>
</section><section><h2 class="section-heading" id="tagging-a-dataset">Tagging a dataset<a class="anchor" aria-label="anchor" href="#tagging-a-dataset"></a></h2>
<hr class="half-width"><p>Most of the human time spent training a model will be spent
pre-processing and labelling data. If we expect our model to label data
with an arbitrary set of labels, we need to give it some idea of what to
look for. We want to make sure we have enough data for the model to
perform at a good enough degree of accuracy for our purpose. Of course,
this number will vary based on what level of performance is “good
enough” and the difficulty of the task. While there’s no set number, a
set of approximately 100,000 tokens is enough to train many NER
tasks.</p>
<p>Fortunately, software exists to help streamline the tagging process.
One open source example of tagging software is Label Studio. However,
it’s not the only option, so feel free to select a data labelling
software that matches your preferences or needs for a given project. An
online demo of Label Studio is available here: <a href="https://labelstud.io/playground" class="external-link uri">https://labelstud.io/playground</a>. It’s also possible to
install locally.</p>
<p>Select “Named Entity Recognition” as the task to see what the
interface would look like if we were doing our own tagging. We can
define our own labels by copying in the following code (minus the
quotations):</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="co">"""</span></span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a><span class="co">&lt;View&gt;</span></span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a><span class="co">  &lt;Labels name="label" toName="text"&gt;</span></span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a><span class="co">    &lt;Label value="Amenity" background="red"/&gt;</span></span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a><span class="co">    &lt;Label value="Cuisine" background="darkorange"/&gt;</span></span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a><span class="co">    &lt;Label value="Dish" background="orange"/&gt;</span></span>
<span id="cb10-7"><a href="#cb10-7" tabindex="-1"></a><span class="co">    &lt;Label value="Hours" background="green"/&gt;</span></span>
<span id="cb10-8"><a href="#cb10-8" tabindex="-1"></a><span class="co">    &lt;Label value="Location" background="darkblue"/&gt;</span></span>
<span id="cb10-9"><a href="#cb10-9" tabindex="-1"></a><span class="co">    &lt;Label value="Price" background="blue"/&gt;</span></span>
<span id="cb10-10"><a href="#cb10-10" tabindex="-1"></a><span class="co">    &lt;Label value="Rating" background="purple"/&gt;</span></span>
<span id="cb10-11"><a href="#cb10-11" tabindex="-1"></a><span class="co">    &lt;Label value="Restaurant_Name" background="#842"/&gt;</span></span>
<span id="cb10-12"><a href="#cb10-12" tabindex="-1"></a><span class="co">  &lt;/Labels&gt;</span></span>
<span id="cb10-13"><a href="#cb10-13" tabindex="-1"></a></span>
<span id="cb10-14"><a href="#cb10-14" tabindex="-1"></a><span class="co">  &lt;Text name="text" value="$text"/&gt;</span></span>
<span id="cb10-15"><a href="#cb10-15" tabindex="-1"></a><span class="co">&lt;/View&gt;</span></span>
<span id="cb10-16"><a href="#cb10-16" tabindex="-1"></a><span class="co">"""</span></span></code></pre>
</div>
<p>In Label Studio, labels can be applied by hitting a number on your
keyboard and highlighting the relevant part of the document. Try doing
so on our example text and looking at the output.</p>
<p>Once done, we will have to export our files for use in our model.
Label Studio supports a number of different types of labelling tasks, so
you may want to use it for tasks other than just NER.</p>
<p>One additional note: There is a github project for direct integration
between label studio and HuggingFace available as well. Given that the
task selected may vary on the model and you may not opt to use Label
Studio for a given project, we will simply point to this project as a
possible resource (<a href="https://github.com/heartexlabs/label-studio-transformers" class="external-link uri">https://github.com/heartexlabs/label-studio-transformers</a>)
rather than use it in this lesson.</p>
</section><section><h2 class="section-heading" id="export-to-desired-format">Export to desired format<a class="anchor" aria-label="anchor" href="#export-to-desired-format"></a></h2>
<hr class="half-width"><p>So, let’s say you’ve finished your tagging project. How do we get
these labels out of label studio and into our model?</p>
<p>Label Studio supports export into many formats, including one called
CoNLL2003. This is the format our test dataset is in. It’s a space
seperated CSV, with words and their tags.</p>
<p>We’ll skip the export step as well, as we already have a prelabeled
set of tags in a similar format published by MIT. For more details about
supported export formats consult the help page for Label Studio here: <a href="https://labelstud.io/guide/export.html" class="external-link uri">https://labelstud.io/guide/export.html</a></p>
<p>At this point, we’ve got all the labelled data we want. We now need
to load our dataset into HuggingFace and then train our model. The
following code will be largely based on the example code from
HuggingFace, substituting in our data for the CoNLL data.</p>
</section><section><h2 class="section-heading" id="loading-our-custom-dataset">Loading our custom dataset<a class="anchor" aria-label="anchor" href="#loading-our-custom-dataset"></a></h2>
<hr class="half-width"><p>Let’s import our carpentries files and helper methods first, as they
contain our data and a loading script.</p>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="co"># Run this cell to mount your Google Drive.</span></span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a><span class="im">from</span> google.colab <span class="im">import</span> drive</span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a>drive.mount(<span class="st">'/content/drive'</span>)</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb12">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a><span class="co"># pip install necessary to access parse module (called from helpers.py)</span></span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a><span class="op">!</span>pip install parse</span></code></pre>
</div>
<p>Finally, lets make our own tweaks to the HuggingFace colab notebook.
We’ll start by importing some key metrics.</p>
<div class="codewrapper sourceCode" id="cb13">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a><span class="im">import</span> datasets</span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a><span class="im">from</span> datasets <span class="im">import</span> load_dataset, Features</span></code></pre>
</div>
<p>The HuggingFace example uses <a href="https://www.aclweb.org/anthology/W03-0419.pdf" class="external-link">CONLL 2003
dataset</a>.</p>
<p>All datasets from huggingface are loaded using scripts. Datasets can
be defined from a JSON or csv file (see the <a href="https://huggingface.co/docs/datasets/loading_datasets.html#from-local-files" class="external-link">Datasets
documentation</a>) but selecting CSV will by default create a new
document for every token and NER tag and will not load the documents
correctly. So we will use a tweaked version of the Conll loading script
instead. Let’s take a look at the regular Conll script first:</p>
<p><a href="https://huggingface.co/datasets/conll2003/tree/main" class="external-link uri">https://huggingface.co/datasets/conll2003/tree/main</a></p>
<p>The loading script is the python file. Usually the loading script is
named after the dataset in question. There are a couple of things we
want to change-</p>
<ol style="list-style-type: decimal"><li>We want to tweak the metadata with citations to reflect where we got
our data. If you created the data, you can add in your own citation
here.</li>
<li>We want to define our own categories for NER_TAGS, to reflect our
new named entities.</li>
<li>The order for our tokens and NER tags is flipped in our data
files.</li>
<li>Delimiters for our data files are tabs instead of spaces.</li>
<li>We will replace the method names with ones appropriate for our
dataset.</li>
</ol><p>Those modifications have been made in our mit_restaurants.py file.
Let’s briefly take a look at that file before we proceed with the
huggingface script. Again, these are modifications, not working from
scratch.</p>
</section><section><h2 class="section-heading" id="huggingface-code">HuggingFace Code<a class="anchor" aria-label="anchor" href="#huggingface-code"></a></h2>
<hr class="half-width"><p>Now that we have a modified huggingface script, let’s load our
data.</p>
<div class="codewrapper sourceCode" id="cb14">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a>ds <span class="op">=</span> load_dataset(<span class="st">"/content/drive/MyDrive/Colab Notebooks/text-analysis/code/mit_restaurants.py"</span>, trust_remote_code<span class="op">=</span><span class="va">True</span>)</span></code></pre>
</div>
<p>How does our dataset compare to the CONLL dataset? Let’s look at a
record and compare.</p>
<div class="codewrapper sourceCode" id="cb15">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a>ds</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb16">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a>label_list <span class="op">=</span> ds[<span class="st">"train"</span>].features[<span class="ss">f"ner_tags"</span>].feature.names</span>
<span id="cb16-2"><a href="#cb16-2" tabindex="-1"></a>label_list</span></code></pre>
</div>
<p>Our data looks pretty similar to the CONLL data now. This is good
since we can now reuse many of the methods listed by HuggingFace in
their Colab notebook.</p>
</section><section><h2 class="section-heading" id="preprocessing-the-data">Preprocessing the data<a class="anchor" aria-label="anchor" href="#preprocessing-the-data"></a></h2>
<hr class="half-width"><p>We start by defining some variables that HuggingFace uses later
on.</p>
<div class="codewrapper sourceCode" id="cb17">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb17-2"><a href="#cb17-2" tabindex="-1"></a></span>
<span id="cb17-3"><a href="#cb17-3" tabindex="-1"></a>task <span class="op">=</span> <span class="st">"ner"</span> <span class="co"># Should be one of "ner", "pos" or "chunk"</span></span>
<span id="cb17-4"><a href="#cb17-4" tabindex="-1"></a>model_checkpoint <span class="op">=</span> <span class="st">"distilbert-base-uncased"</span></span>
<span id="cb17-5"><a href="#cb17-5" tabindex="-1"></a>batch_size <span class="op">=</span> <span class="dv">16</span></span>
<span id="cb17-6"><a href="#cb17-6" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">"cuda"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span>)</span></code></pre>
</div>
<p>Next, we create our special BERT tokenizer.</p>
<div class="codewrapper sourceCode" id="cb18">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoTokenizer</span>
<span id="cb18-2"><a href="#cb18-2" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(model_checkpoint)</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb19">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" tabindex="-1"></a>example <span class="op">=</span> ds[<span class="st">"train"</span>][<span class="dv">4</span>]</span>
<span id="cb19-2"><a href="#cb19-2" tabindex="-1"></a>tokenized_input <span class="op">=</span> tokenizer(example[<span class="st">"tokens"</span>], is_split_into_words<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb19-3"><a href="#cb19-3" tabindex="-1"></a>tokens <span class="op">=</span> tokenizer.convert_ids_to_tokens(tokenized_input[<span class="st">"input_ids"</span>])</span>
<span id="cb19-4"><a href="#cb19-4" tabindex="-1"></a><span class="bu">print</span>(tokens)</span></code></pre>
</div>
<p>Since our words are broken into just words, and the BERT tokenizer
sometimes breaks words into subwords, we need to retokenize our words.
We also need to make sure that when we do this, the labels we created
don’t get misaligned. More details on these methods are available
through HuggingFace, but we will simply use their code to do this.</p>
<div class="codewrapper sourceCode" id="cb20">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" tabindex="-1"></a>word_ids <span class="op">=</span> tokenized_input.word_ids()</span>
<span id="cb20-2"><a href="#cb20-2" tabindex="-1"></a>aligned_labels <span class="op">=</span> [<span class="op">-</span><span class="dv">100</span> <span class="cf">if</span> i <span class="kw">is</span> <span class="va">None</span> <span class="cf">else</span> example[<span class="ss">f"</span><span class="sc">{</span>task<span class="sc">}</span><span class="ss">_tags"</span>][i] <span class="cf">for</span> i <span class="kw">in</span> word_ids]</span>
<span id="cb20-3"><a href="#cb20-3" tabindex="-1"></a>label_all_tokens <span class="op">=</span> <span class="va">True</span></span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb21">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" tabindex="-1"></a><span class="kw">def</span> tokenize_and_align_labels(examples):</span>
<span id="cb21-2"><a href="#cb21-2" tabindex="-1"></a>    tokenized_inputs <span class="op">=</span> tokenizer(examples[<span class="st">"tokens"</span>], truncation<span class="op">=</span><span class="va">True</span>, is_split_into_words<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb21-3"><a href="#cb21-3" tabindex="-1"></a></span>
<span id="cb21-4"><a href="#cb21-4" tabindex="-1"></a>    labels <span class="op">=</span> []</span>
<span id="cb21-5"><a href="#cb21-5" tabindex="-1"></a>    <span class="cf">for</span> i, label <span class="kw">in</span> <span class="bu">enumerate</span>(examples[<span class="ss">f"</span><span class="sc">{</span>task<span class="sc">}</span><span class="ss">_tags"</span>]):</span>
<span id="cb21-6"><a href="#cb21-6" tabindex="-1"></a>        word_ids <span class="op">=</span> tokenized_inputs.word_ids(batch_index<span class="op">=</span>i)</span>
<span id="cb21-7"><a href="#cb21-7" tabindex="-1"></a>        previous_word_idx <span class="op">=</span> <span class="va">None</span></span>
<span id="cb21-8"><a href="#cb21-8" tabindex="-1"></a>        label_ids <span class="op">=</span> []</span>
<span id="cb21-9"><a href="#cb21-9" tabindex="-1"></a>        <span class="cf">for</span> word_idx <span class="kw">in</span> word_ids:</span>
<span id="cb21-10"><a href="#cb21-10" tabindex="-1"></a>            <span class="co"># Special tokens have a word id that is None. We set the label to -100 so they are automatically</span></span>
<span id="cb21-11"><a href="#cb21-11" tabindex="-1"></a>            <span class="co"># ignored in the loss function.</span></span>
<span id="cb21-12"><a href="#cb21-12" tabindex="-1"></a>            <span class="cf">if</span> word_idx <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb21-13"><a href="#cb21-13" tabindex="-1"></a>                label_ids.append(<span class="op">-</span><span class="dv">100</span>)</span>
<span id="cb21-14"><a href="#cb21-14" tabindex="-1"></a>            <span class="co"># We set the label for the first token of each word.</span></span>
<span id="cb21-15"><a href="#cb21-15" tabindex="-1"></a>            <span class="cf">elif</span> word_idx <span class="op">!=</span> previous_word_idx:</span>
<span id="cb21-16"><a href="#cb21-16" tabindex="-1"></a>                label_ids.append(label[word_idx])</span>
<span id="cb21-17"><a href="#cb21-17" tabindex="-1"></a>            <span class="co"># For the other tokens in a word, we set the label to either the current label or -100, depending on</span></span>
<span id="cb21-18"><a href="#cb21-18" tabindex="-1"></a>            <span class="co"># the label_all_tokens flag.</span></span>
<span id="cb21-19"><a href="#cb21-19" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb21-20"><a href="#cb21-20" tabindex="-1"></a>                label_ids.append(label[word_idx] <span class="cf">if</span> label_all_tokens <span class="cf">else</span> <span class="op">-</span><span class="dv">100</span>)</span>
<span id="cb21-21"><a href="#cb21-21" tabindex="-1"></a>            previous_word_idx <span class="op">=</span> word_idx</span>
<span id="cb21-22"><a href="#cb21-22" tabindex="-1"></a></span>
<span id="cb21-23"><a href="#cb21-23" tabindex="-1"></a>        labels.append(label_ids)</span>
<span id="cb21-24"><a href="#cb21-24" tabindex="-1"></a></span>
<span id="cb21-25"><a href="#cb21-25" tabindex="-1"></a>    tokenized_inputs[<span class="st">"labels"</span>] <span class="op">=</span> labels</span>
<span id="cb21-26"><a href="#cb21-26" tabindex="-1"></a>    <span class="cf">return</span> tokenized_inputs</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb22">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" tabindex="-1"></a>tokenized_datasets <span class="op">=</span> ds.<span class="bu">map</span>(tokenize_and_align_labels, batched<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb22-2"><a href="#cb22-2" tabindex="-1"></a><span class="bu">print</span>(tokenized_datasets)</span></code></pre>
</div>
<p>The preprocessed features we’ve just added will be the ones used to
actually train the model.</p>
</section><section><h2 class="section-heading" id="fine-tuning-the-model">Fine-tuning the model<a class="anchor" aria-label="anchor" href="#fine-tuning-the-model"></a></h2>
<hr class="half-width"><p>Now that our data is ready, we can download the pretrained LLM model.
Since our task is token classification, we use the
<code>AutoModelForTokenClassification</code> class. Before we do though,
we want to specify the mapping for ids and labels to our model so it
does not simply return CLASS_1, CLASS_2 and so on.</p>
<div class="codewrapper sourceCode" id="cb23">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" tabindex="-1"></a>id2label <span class="op">=</span> {</span>
<span id="cb23-2"><a href="#cb23-2" tabindex="-1"></a>    <span class="dv">0</span>: <span class="st">"O"</span>,</span>
<span id="cb23-3"><a href="#cb23-3" tabindex="-1"></a>    <span class="dv">1</span>: <span class="st">"B-Amenity"</span>,</span>
<span id="cb23-4"><a href="#cb23-4" tabindex="-1"></a>    <span class="dv">2</span>: <span class="st">"I-Amenity"</span>,</span>
<span id="cb23-5"><a href="#cb23-5" tabindex="-1"></a>    <span class="dv">3</span>: <span class="st">"B-Cuisine"</span>,</span>
<span id="cb23-6"><a href="#cb23-6" tabindex="-1"></a>    <span class="dv">4</span>: <span class="st">"I-Cuisine"</span>,</span>
<span id="cb23-7"><a href="#cb23-7" tabindex="-1"></a>    <span class="dv">5</span>: <span class="st">"B-Dish"</span>,</span>
<span id="cb23-8"><a href="#cb23-8" tabindex="-1"></a>    <span class="dv">6</span>: <span class="st">"I-Dish"</span>,</span>
<span id="cb23-9"><a href="#cb23-9" tabindex="-1"></a>    <span class="dv">7</span>: <span class="st">"B-Hours"</span>,</span>
<span id="cb23-10"><a href="#cb23-10" tabindex="-1"></a>    <span class="dv">8</span>: <span class="st">"I-Hours"</span>,</span>
<span id="cb23-11"><a href="#cb23-11" tabindex="-1"></a>    <span class="dv">9</span>: <span class="st">"B-Location"</span>,</span>
<span id="cb23-12"><a href="#cb23-12" tabindex="-1"></a>    <span class="dv">10</span>: <span class="st">"I-Location"</span>,</span>
<span id="cb23-13"><a href="#cb23-13" tabindex="-1"></a>    <span class="dv">11</span>: <span class="st">"B-Price"</span>,</span>
<span id="cb23-14"><a href="#cb23-14" tabindex="-1"></a>    <span class="dv">12</span>: <span class="st">"I-Price"</span>,</span>
<span id="cb23-15"><a href="#cb23-15" tabindex="-1"></a>    <span class="dv">13</span>: <span class="st">"B-Rating"</span>,</span>
<span id="cb23-16"><a href="#cb23-16" tabindex="-1"></a>    <span class="dv">14</span>: <span class="st">"I-Rating"</span>,</span>
<span id="cb23-17"><a href="#cb23-17" tabindex="-1"></a>    <span class="dv">15</span>: <span class="st">"B-Restaurant_Name"</span>,</span>
<span id="cb23-18"><a href="#cb23-18" tabindex="-1"></a>    <span class="dv">16</span>: <span class="st">"I-Restaurant_Name"</span>,</span>
<span id="cb23-19"><a href="#cb23-19" tabindex="-1"></a>}</span>
<span id="cb23-20"><a href="#cb23-20" tabindex="-1"></a></span>
<span id="cb23-21"><a href="#cb23-21" tabindex="-1"></a>label2id <span class="op">=</span> {</span>
<span id="cb23-22"><a href="#cb23-22" tabindex="-1"></a>    <span class="st">"O"</span>: <span class="dv">0</span>,</span>
<span id="cb23-23"><a href="#cb23-23" tabindex="-1"></a>    <span class="st">"B-Amenity"</span>: <span class="dv">1</span>,</span>
<span id="cb23-24"><a href="#cb23-24" tabindex="-1"></a>    <span class="st">"I-Amenity"</span>: <span class="dv">2</span>,</span>
<span id="cb23-25"><a href="#cb23-25" tabindex="-1"></a>    <span class="st">"B-Cuisine"</span>: <span class="dv">3</span>,</span>
<span id="cb23-26"><a href="#cb23-26" tabindex="-1"></a>    <span class="st">"I-Cuisine"</span>: <span class="dv">4</span>,</span>
<span id="cb23-27"><a href="#cb23-27" tabindex="-1"></a>    <span class="st">"B-Dish"</span>: <span class="dv">5</span>,</span>
<span id="cb23-28"><a href="#cb23-28" tabindex="-1"></a>    <span class="st">"I-Dish"</span>: <span class="dv">6</span>,</span>
<span id="cb23-29"><a href="#cb23-29" tabindex="-1"></a>    <span class="st">"B-Hours"</span>: <span class="dv">7</span>,</span>
<span id="cb23-30"><a href="#cb23-30" tabindex="-1"></a>    <span class="st">"I-Hours"</span>: <span class="dv">8</span>,</span>
<span id="cb23-31"><a href="#cb23-31" tabindex="-1"></a>    <span class="st">"B-Location"</span>: <span class="dv">9</span>,</span>
<span id="cb23-32"><a href="#cb23-32" tabindex="-1"></a>    <span class="st">"I-Location"</span>: <span class="dv">10</span>,</span>
<span id="cb23-33"><a href="#cb23-33" tabindex="-1"></a>    <span class="st">"B-Price"</span>: <span class="dv">11</span>,</span>
<span id="cb23-34"><a href="#cb23-34" tabindex="-1"></a>    <span class="st">"I-Price"</span>: <span class="dv">12</span>,</span>
<span id="cb23-35"><a href="#cb23-35" tabindex="-1"></a>    <span class="st">"B-Rating"</span>: <span class="dv">13</span>,</span>
<span id="cb23-36"><a href="#cb23-36" tabindex="-1"></a>    <span class="st">"I-Rating"</span>: <span class="dv">14</span>,</span>
<span id="cb23-37"><a href="#cb23-37" tabindex="-1"></a>    <span class="st">"B-Restaurant_Name"</span>: <span class="dv">15</span>,</span>
<span id="cb23-38"><a href="#cb23-38" tabindex="-1"></a>    <span class="st">"I-Restaurant_Name"</span>: <span class="dv">16</span>,</span>
<span id="cb23-39"><a href="#cb23-39" tabindex="-1"></a>}</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb24">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoModelForTokenClassification, TrainingArguments, Trainer</span>
<span id="cb24-2"><a href="#cb24-2" tabindex="-1"></a></span>
<span id="cb24-3"><a href="#cb24-3" tabindex="-1"></a>model <span class="op">=</span> AutoModelForTokenClassification.from_pretrained(model_checkpoint, id2label<span class="op">=</span>id2label, label2id<span class="op">=</span>label2id, num_labels<span class="op">=</span><span class="bu">len</span>(label_list)).to(device)</span></code></pre>
</div>
<pre><code>Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.</code></pre>
<p>The warning is telling us we are throwing away some weights. We’re
training our model, so we should be fine.</p>
<p>##Configuration Arguments</p>
<p>Next, we configure our trainer. The are lots of settings here but the
defaults are fine. More detailed documentation on what each of these
mean are available through Huggingface: <a href="https://huggingface.co/transformers/main_classes/trainer.html#transformers.TrainingArguments" class="external-link"><code>TrainingArguments</code></a>,</p>
<div class="codewrapper sourceCode" id="cb26">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" tabindex="-1"></a>model_name <span class="op">=</span> model_checkpoint.split(<span class="st">"/"</span>)[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb26-2"><a href="#cb26-2" tabindex="-1"></a>args <span class="op">=</span> TrainingArguments(</span>
<span id="cb26-3"><a href="#cb26-3" tabindex="-1"></a>    <span class="co">#f"{model_name}-finetuned-{task}",</span></span>
<span id="cb26-4"><a href="#cb26-4" tabindex="-1"></a>    <span class="ss">f"</span><span class="sc">{</span>model_name<span class="sc">}</span><span class="ss">-carpentries-restaurant-ner"</span>,</span>
<span id="cb26-5"><a href="#cb26-5" tabindex="-1"></a>    learning_rate<span class="op">=</span><span class="fl">2e-5</span>,</span>
<span id="cb26-6"><a href="#cb26-6" tabindex="-1"></a>    per_device_train_batch_size<span class="op">=</span>batch_size,</span>
<span id="cb26-7"><a href="#cb26-7" tabindex="-1"></a>    per_device_eval_batch_size<span class="op">=</span>batch_size,</span>
<span id="cb26-8"><a href="#cb26-8" tabindex="-1"></a>    num_train_epochs<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb26-9"><a href="#cb26-9" tabindex="-1"></a>    weight_decay<span class="op">=</span><span class="fl">0.01</span>,</span>
<span id="cb26-10"><a href="#cb26-10" tabindex="-1"></a>    report_to<span class="op">=</span><span class="st">"none"</span>,</span>
<span id="cb26-11"><a href="#cb26-11" tabindex="-1"></a>    eval_strategy<span class="op">=</span><span class="st">"epoch"</span>,</span>
<span id="cb26-12"><a href="#cb26-12" tabindex="-1"></a>    save_strategy<span class="op">=</span><span class="st">"epoch"</span>,</span>
<span id="cb26-13"><a href="#cb26-13" tabindex="-1"></a>    load_best_model_at_end<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb26-14"><a href="#cb26-14" tabindex="-1"></a>    push_to_hub<span class="op">=</span><span class="va">False</span>, <span class="co">#You can have your model automatically pushed to HF if you uncomment this and log in.</span></span>
<span id="cb26-15"><a href="#cb26-15" tabindex="-1"></a>)</span></code></pre>
</div>
</section><section><h2 class="section-heading" id="collator">Collator<a class="anchor" aria-label="anchor" href="#collator"></a></h2>
<hr class="half-width"><p>One finicky aspect of the model is that all of the inputs have to be
the same size. When the sizes do not match, something called a data
collator is used to batch our processed examples together and pad them
to the same size.</p>
<div class="codewrapper sourceCode" id="cb27">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> DataCollatorForTokenClassification</span>
<span id="cb27-2"><a href="#cb27-2" tabindex="-1"></a></span>
<span id="cb27-3"><a href="#cb27-3" tabindex="-1"></a>data_collator <span class="op">=</span> DataCollatorForTokenClassification(tokenizer)</span></code></pre>
</div>
</section><section><h2 class="section-heading" id="metrics">Metrics<a class="anchor" aria-label="anchor" href="#metrics"></a></h2>
<hr class="half-width"><p>The last thing we want to define is the metric by which we evaluate
how our model did. We will use <a href="https://github.com/chakki-works/seqeval" class="external-link"><code>seqeval</code></a>.
The metric used will vary based on the task- make sure to check the
huggingface notebooks for the appropriate metric for a given task.</p>
<div class="codewrapper sourceCode" id="cb28">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" tabindex="-1"></a><span class="im">import</span> evaluate</span>
<span id="cb28-2"><a href="#cb28-2" tabindex="-1"></a></span>
<span id="cb28-3"><a href="#cb28-3" tabindex="-1"></a>seqeval <span class="op">=</span> evaluate.load(<span class="st">"seqeval"</span>)</span></code></pre>
</div>
</section><section><h2 class="section-heading" id="post-processing">Post Processing<a class="anchor" aria-label="anchor" href="#post-processing"></a></h2>
<hr class="half-width"><p>Per HuggingFace- we need to do a bit of post-processing on our
predictions. The following function and description is taken directly
from HuggingFace. The function does the following: - Selected the
predicted index (with the maximum logit) for each token - Converts it to
its string label - Ignore everywhere we set a label of -100</p>
<div class="codewrapper sourceCode" id="cb29">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb29-2"><a href="#cb29-2" tabindex="-1"></a></span>
<span id="cb29-3"><a href="#cb29-3" tabindex="-1"></a><span class="kw">def</span> compute_metrics(p):</span>
<span id="cb29-4"><a href="#cb29-4" tabindex="-1"></a>    predictions, labels <span class="op">=</span> p</span>
<span id="cb29-5"><a href="#cb29-5" tabindex="-1"></a>    predictions <span class="op">=</span> np.argmax(predictions, axis<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb29-6"><a href="#cb29-6" tabindex="-1"></a></span>
<span id="cb29-7"><a href="#cb29-7" tabindex="-1"></a>    <span class="co"># Remove ignored index (special tokens)</span></span>
<span id="cb29-8"><a href="#cb29-8" tabindex="-1"></a>    true_predictions <span class="op">=</span> [</span>
<span id="cb29-9"><a href="#cb29-9" tabindex="-1"></a>        [label_list[p] <span class="cf">for</span> (p, l) <span class="kw">in</span> <span class="bu">zip</span>(prediction, label) <span class="cf">if</span> l <span class="op">!=</span> <span class="op">-</span><span class="dv">100</span>]</span>
<span id="cb29-10"><a href="#cb29-10" tabindex="-1"></a>        <span class="cf">for</span> prediction, label <span class="kw">in</span> <span class="bu">zip</span>(predictions, labels)</span>
<span id="cb29-11"><a href="#cb29-11" tabindex="-1"></a>    ]</span>
<span id="cb29-12"><a href="#cb29-12" tabindex="-1"></a>    true_labels <span class="op">=</span> [</span>
<span id="cb29-13"><a href="#cb29-13" tabindex="-1"></a>        [label_list[l] <span class="cf">for</span> (p, l) <span class="kw">in</span> <span class="bu">zip</span>(prediction, label) <span class="cf">if</span> l <span class="op">!=</span> <span class="op">-</span><span class="dv">100</span>]</span>
<span id="cb29-14"><a href="#cb29-14" tabindex="-1"></a>        <span class="cf">for</span> prediction, label <span class="kw">in</span> <span class="bu">zip</span>(predictions, labels)</span>
<span id="cb29-15"><a href="#cb29-15" tabindex="-1"></a>    ]</span>
<span id="cb29-16"><a href="#cb29-16" tabindex="-1"></a></span>
<span id="cb29-17"><a href="#cb29-17" tabindex="-1"></a>    results <span class="op">=</span> metric.compute(predictions<span class="op">=</span>true_predictions, references<span class="op">=</span>true_labels)</span>
<span id="cb29-18"><a href="#cb29-18" tabindex="-1"></a>    <span class="cf">return</span> {</span>
<span id="cb29-19"><a href="#cb29-19" tabindex="-1"></a>        <span class="st">"precision"</span>: results[<span class="st">"overall_precision"</span>],</span>
<span id="cb29-20"><a href="#cb29-20" tabindex="-1"></a>        <span class="st">"recall"</span>: results[<span class="st">"overall_recall"</span>],</span>
<span id="cb29-21"><a href="#cb29-21" tabindex="-1"></a>        <span class="st">"f1"</span>: results[<span class="st">"overall_f1"</span>],</span>
<span id="cb29-22"><a href="#cb29-22" tabindex="-1"></a>        <span class="st">"accuracy"</span>: results[<span class="st">"overall_accuracy"</span>],</span>
<span id="cb29-23"><a href="#cb29-23" tabindex="-1"></a>    }</span></code></pre>
</div>
<p>Finally, after all of the preparation we’ve done, we’re ready to
create a Trainer to train our model.</p>
<div class="codewrapper sourceCode" id="cb30">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" tabindex="-1"></a>trainer <span class="op">=</span> Trainer(</span>
<span id="cb30-2"><a href="#cb30-2" tabindex="-1"></a>    model,</span>
<span id="cb30-3"><a href="#cb30-3" tabindex="-1"></a>    args,</span>
<span id="cb30-4"><a href="#cb30-4" tabindex="-1"></a>    train_dataset<span class="op">=</span>tokenized_datasets[<span class="st">"train"</span>],</span>
<span id="cb30-5"><a href="#cb30-5" tabindex="-1"></a>    eval_dataset<span class="op">=</span>tokenized_datasets[<span class="st">"validation"</span>],</span>
<span id="cb30-6"><a href="#cb30-6" tabindex="-1"></a>    data_collator<span class="op">=</span>data_collator,</span>
<span id="cb30-7"><a href="#cb30-7" tabindex="-1"></a>    tokenizer<span class="op">=</span>tokenizer,</span>
<span id="cb30-8"><a href="#cb30-8" tabindex="-1"></a>    compute_metrics<span class="op">=</span>compute_metrics,</span>
<span id="cb30-9"><a href="#cb30-9" tabindex="-1"></a>)</span></code></pre>
</div>
<p>We can now finetune our model by just calling the <code>train</code>
method. Note that this step will take about 5 minutes if you are running
it on a GPU, and 4+ hours if you are not.</p>
<div class="codewrapper sourceCode" id="cb31">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Training starts NOW"</span>)</span>
<span id="cb31-2"><a href="#cb31-2" tabindex="-1"></a>trainer.train()</span></code></pre>
</div>
<p>We’ve done it! We’ve fine-tuned the model for our task. Now that it’s
trained, we want to save our work so that we can reuse the model
whenever we wish. A saved version of this model has also been published
through huggingface, so if you are using a CPU, skip the remaining
evaluation steps and launch a new terminal so you can participate in
the</p>
<div class="codewrapper sourceCode" id="cb32">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" tabindex="-1"></a>trainer.save_model(<span class="st">"/content/drive/MyDrive/Colab Notebooks/text-analysis/ft-model"</span>)</span></code></pre>
</div>
</section><section><h2 class="section-heading" id="evaluation-metrics-for-ner">Evaluation Metrics for NER<a class="anchor" aria-label="anchor" href="#evaluation-metrics-for-ner"></a></h2>
<hr class="half-width"><p>We have some NER evaluation metrics, so let’s discuss what they mean.
Accuracy is the most obvious metric for NER. Accuracy is the number of
correctly labelled entities divided by the number of total entities. The
problem with this metric can be illustrated by supposing we want a model
to identify a needle in a haystack. A model that identifies everything
as hay would be highly accurate, as most of the entities in a haystack
ARE hay, but it wouldn’t allow us to find the rare needles we’re looking
for. Similarly, our named entities will likely not make up most of our
documents, so accuracy is not a good metric.</p>
<p>We can classify recommendations made by a model into four categories-
true positive, true negative, false positive and false negative.</p>
<table class="table"><colgroup><col width="38%"><col width="28%"><col width="32%"></colgroup><thead><tr class="header"><th></th>
<th>Document is in our category</th>
<th>Document is not in our category</th>
</tr></thead><tbody><tr class="odd"><td>Model predicts it is in our category</td>
<td>True Positive (TP)</td>
<td>False Positive (FP)</td>
</tr><tr class="even"><td>Model predicts it is not in category</td>
<td>False Negative (FN)</td>
<td>True Negative (TN)</td>
</tr></tbody></table><p><strong>Precision</strong> is TP / TP + FP. It measures how correct
your model’s labels were among the set of entities the model predicted
were part of the class. This measure could be gamed, however, by being
very conservative about making positive labels and only doing so when
the model was absolutely certain, possibly missing relevant
entities.</p>
<p><strong>Recall</strong> is TP / TP + FN. It measures how correct your
model’s labels are among the set of every entity actually belonging to
the class. Recall could be trivally gamed by simply classify all
documents as being part of the class.</p>
<p>The <strong>F1</strong> score is a harmonic mean between the two,
ensuring the model is neither too conservative or too prone to
overclassification.</p>
<p>Now let’s see how our model did. We’ll run a more detailed evaluation
step from HuggingFace if desired, to see how well our model performed.
It is likely a good idea to have these metrics so that you can compare
your performance to more generic models for the task.</p>
<div class="codewrapper sourceCode" id="cb33">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" tabindex="-1"></a><span class="im">from</span> evaluate <span class="im">import</span> evaluator</span>
<span id="cb33-2"><a href="#cb33-2" tabindex="-1"></a></span>
<span id="cb33-3"><a href="#cb33-3" tabindex="-1"></a>task_evaluator <span class="op">=</span> evaluator(<span class="st">"ner"</span>)</span>
<span id="cb33-4"><a href="#cb33-4" tabindex="-1"></a>data<span class="op">=</span> load_dataset(<span class="st">"/content/drive/MyDrive/Colab Notebooks/text-analysis/code/mit_restaurants.py"</span>, split<span class="op">=</span><span class="st">"test"</span>, trust_remote_code<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb33-5"><a href="#cb33-5" tabindex="-1"></a></span>
<span id="cb33-6"><a href="#cb33-6" tabindex="-1"></a>eval_results <span class="op">=</span> task_evaluator.compute(</span>
<span id="cb33-7"><a href="#cb33-7" tabindex="-1"></a>    model_or_pipeline<span class="op">=</span><span class="st">"/content/drive/MyDrive/Colab Notebooks/text-analysis/ft-model"</span>,</span>
<span id="cb33-8"><a href="#cb33-8" tabindex="-1"></a>    data<span class="op">=</span>data,</span>
<span id="cb33-9"><a href="#cb33-9" tabindex="-1"></a>)</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb34">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" tabindex="-1"></a><span class="cf">for</span> r <span class="kw">in</span> eval_results:</span>
<span id="cb34-2"><a href="#cb34-2" tabindex="-1"></a>  <span class="bu">print</span>(r, eval_results[r])</span></code></pre>
</div>
<p>Whether a F1 score of .779 is ‘good enough’ depends on the
performance of other models, how difficult the task is, and so on. It
may be good enough for our needs, or we may want to collect more data,
train on a bigger model, or adjust our parameters. For the purposes of
the workshop, we will say that this is fine.</p>
</section><section><h2 class="section-heading" id="using-our-model">Using our Model<a class="anchor" aria-label="anchor" href="#using-our-model"></a></h2>
<hr class="half-width"><p>Now that we’ve created our model, we can run it just like we did the
pretrained models. The code below should do just that. Feel free to
compose your own example and see how well the model performs!</p>
<div class="codewrapper sourceCode" id="cb35">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> pipeline</span>
<span id="cb35-2"><a href="#cb35-2" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoModelForTokenClassification</span>
<span id="cb35-3"><a href="#cb35-3" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoTokenizer</span>
<span id="cb35-4"><a href="#cb35-4" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> TokenClassificationPipeline</span>
<span id="cb35-5"><a href="#cb35-5" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb35-6"><a href="#cb35-6" tabindex="-1"></a></span>
<span id="cb35-7"><a href="#cb35-7" tabindex="-1"></a><span class="co">#Colab code</span></span>
<span id="cb35-8"><a href="#cb35-8" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(<span class="st">"distilbert-base-uncased"</span>)</span>
<span id="cb35-9"><a href="#cb35-9" tabindex="-1"></a>model <span class="op">=</span> AutoModelForTokenClassification.from_pretrained(<span class="st">"/content/drive/MyDrive/Colab Notebooks/text-analysis/ft-model"</span>)</span>
<span id="cb35-10"><a href="#cb35-10" tabindex="-1"></a>nlp <span class="op">=</span> pipeline(<span class="st">"ner"</span>, model<span class="op">=</span>model, tokenizer<span class="op">=</span>tokenizer, aggregation_strategy<span class="op">=</span><span class="st">"first"</span>)</span>
<span id="cb35-11"><a href="#cb35-11" tabindex="-1"></a></span>
<span id="cb35-12"><a href="#cb35-12" tabindex="-1"></a><span class="co">#This code imports this model, which I've uploaded to HuggingFace.</span></span>
<span id="cb35-13"><a href="#cb35-13" tabindex="-1"></a><span class="co">#tokenizer = AutoTokenizer.from_pretrained("karlholten/distilbert-carpentries-restaurant-ner")</span></span>
<span id="cb35-14"><a href="#cb35-14" tabindex="-1"></a><span class="co">#model = AutoModelForTokenClassification.from_pretrained("karlholten/distilbert-carpentries-restaurant-ner")</span></span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb36">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" tabindex="-1"></a>EXAMPLE <span class="op">=</span> <span class="st">"where is a four star restaurant in milwaukee with tapas"</span></span>
<span id="cb36-2"><a href="#cb36-2" tabindex="-1"></a>ner_results <span class="op">=</span> nlp(EXAMPLE)</span>
<span id="cb36-3"><a href="#cb36-3" tabindex="-1"></a><span class="cf">for</span> entity <span class="kw">in</span> ner_results:</span>
<span id="cb36-4"><a href="#cb36-4" tabindex="-1"></a>  <span class="bu">print</span>(entity)</span></code></pre>
</div>
</section><section><h2 class="section-heading" id="outro">Outro<a class="anchor" aria-label="anchor" href="#outro"></a></h2>
<hr class="half-width"><p>That’s it! Let’s review briefly what we have done. We’ve discussed
how to select a task. We used a HuggingFace example to help decide on a
data format, and looked over it to get an idea of what the model
expects. We went over Label Studio, one way to label your own data. We
retokenized our example data and fine-tuned a model. Then we went over
the results of our model.</p>
<p>LLM’s are the state-of-the-art for many types of task, and now you
have an idea of how to use and even fine tune them in your own research.
Our next lesson will discuss the ethics and implications of text
analysis.</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul><li>HuggingFace has many examples of LLMs you can fine-tune.</li>
<li>Examine preexisting examples to get an idea of what your model
expects.</li>
<li>Label Studio and other tagging software allows you to easily tag
your own data.</li>
<li>Looking at common metrics used and other models performance in your
subject area will give you an idea of how your model did.</li>
</ul></div>
</div>
</div>
</section></div> <!-- / div.lesson-content -->
    </main><!-- / main#main-content.main-content --><nav class="bottom-pagination mx-md-4" aria-label="Previous and Next Chapter"><div class="d-block d-sm-block d-md-none">
        <a class="chapter-link" href="09-wordEmbed_train-word2vec.html"><i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>Previous</a>
        <a class="chapter-link float-end" href="11-ethics.html">Next<i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i></a>
      </div>
      <!-- content for large screens -->
      <div class="d-none d-sm-none d-md-block">
        <a class="chapter-link" href="09-wordEmbed_train-word2vec.html" rel="prev">
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>
          Previous: Training Word2Vec
        </a>
        <a class="chapter-link float-end" href="11-ethics.html" rel="next">
          Next: Ethics and Text...
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i>
        </a>
      </div>
    </nav></div> <!-- / div.primary-content.col-xs-12 -->
<!-- END:   inst/pkgdown/templates/content-instructor.html-->

      </div><!--/div.row-->
      		<footer class="row footer mx-md-3"><hr><div class="col-md-6">
        <p>This lesson is subject to the <a href="CODE_OF_CONDUCT.html">Code of Conduct</a></p>
        <p>

        <a href="https://github.com/carpentries-incubator/python-text-analysis/edit/main/episodes/10-finetuning-transformers.md" class="external-link">Edit on GitHub</a>

	
        | <a href="https://github.com/carpentries-incubator/python-text-analysis/blob/main/CONTRIBUTING.md" class="external-link">Contributing</a>
        | <a href="https://github.com/carpentries-incubator/python-text-analysis/" class="external-link">Source</a></p>
        <p>
        <a href="https://github.com/carpentries-incubator/python-text-analysis/blob/main/" class="external-link">Cite</a>
        | <a href="mailto:team@carpentries.org">Contact</a> | <a href="https://carpentries.org/about/" class="external-link">About</a></p>
		</div>
		<div class="col-md-6">

        <p>Materials licensed under <a href="LICENSE.html">CC-BY 4.0</a> by the authors</p>

        <p>Template licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0/" class="external-link">CC-BY 4.0</a> by <a href="https://carpentries.org/" class="external-link">The Carpentries</a></p>
        <p>Built with <a href="https://github.com/carpentries/sandpaper/tree/0.17.3" class="external-link">sandpaper (0.17.3)</a>, <a href="https://github.com/carpentries/pegboard/tree/0.7.9" class="external-link">pegboard (0.7.9)</a>, and <a href="https://github.com/carpentries/varnish/tree/1.0.9" class="external-link">varnish (1.0.9)</a></p>
		</div>
		</footer></div> <!-- / div.container -->
	<div id="to-top">
		<a href="#top">
      <i class="search-icon" data-feather="arrow-up" role="img" aria-label="Back To Top"></i><br><!-- <span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top --><span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top
		</a>
	</div>
  <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "LearningResource",
  "@id": "https://carpentries-incubator.github.io/python-text-analysis/10-finetuning-transformers.html",
  "inLanguage": "en",
  "dct:conformsTo": "https://bioschemas.org/profiles/LearningResource/1.0-RELEASE",
  "description": "A Carpentries Lesson teaching foundational data and coding skills to researchers worldwide",
  "keywords": "software, data, lesson, The Carpentries",
  "name": "Finetuning LLMs",
  "creativeWorkStatus": "active",
  "url": "https://carpentries-incubator.github.io/python-text-analysis/10-finetuning-transformers.html",
  "identifier": "https://carpentries-incubator.github.io/python-text-analysis/10-finetuning-transformers.html",
  "dateCreated": "2020-10-12",
  "dateModified": "2025-05-01",
  "datePublished": "2025-12-16"
}

  </script><script>
		feather.replace();
	</script><!-- Matomo --><script>
          var _paq = window._paq = window._paq || [];
          /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
          _paq.push(["setDocumentTitle", document.domain + "/" + document.title]);
          _paq.push(["setDomains", ["*.lessons.carpentries.org","*.datacarpentry.github.io","*.datacarpentry.org","*.librarycarpentry.github.io","*.librarycarpentry.org","*.swcarpentry.github.io", "*.carpentries.github.io"]]);
          _paq.push(["setDoNotTrack", true]);
          _paq.push(["disableCookies"]);
          _paq.push(["trackPageView"]);
          _paq.push(["enableLinkTracking"]);
          (function() {
              var u="https://matomo.carpentries.org/";
              _paq.push(["setTrackerUrl", u+"matomo.php"]);
              _paq.push(["setSiteId", "1"]);
              var d=document, g=d.createElement("script"), s=d.getElementsByTagName("script")[0];
              g.async=true; g.src="https://matomo.carpentries.org/matomo.js"; s.parentNode.insertBefore(g,s);
          })();
        </script><!-- End Matomo Code --></body></html><!-- END:   inst/pkgdown/templates/layout.html-->

